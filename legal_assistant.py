# ==============================================================================
# ASSISTANT JURIDIQUE IA - VERSION FINALE "EXPERT-PRUDENT"
# ==============================================================================

import os
import requests
import json
import io
import time
from PyPDF2 import PdfReader
import google.generativeai as genai
from dotenv import load_dotenv
from firecrawl import FirecrawlApp
from fastapi import FastAPI
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
import numpy as np

# --- CONFIGURATION & GLOBALS ---
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
FIRECRAWL_API_KEY = os.getenv("FIRECRAWL_API_KEY")
SERPER_API_KEY = os.getenv("SERPER_API_KEY")
genai.configure(api_key=GEMINI_API_KEY)

GOVERNMENT_SITES_DATABASE = {
    "France": [".gouv.fr"], "Gabon": [".gouv.ga"], "USA": [".gov"],
    "UK": [".gov.uk"], "Canada": [".gc.ca"], "Cameroun": [".cm", "impots.cm"],
}
api_cache = {}

# --- MODÃˆLES DE DONNÃ‰ES Pydantic ---
class QueryRequest(BaseModel): question: str; country: str
class AnswerResponse(BaseModel): answer: str; source_url: str | None
class SearchPlan(BaseModel):
    requires_search: bool
    reasoning: str
    search_queries: list[str]
    target_domains: list[str]

# --- INITIALISATION DE L'APPLICATION FastAPI ---
app = FastAPI()
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])


# --- FONCTIONS LOGIQUES DE L'AGENT ---

def create_search_plan(question: str, country: str) -> SearchPlan:
    print(f"ğŸ¤” Ã‰tape 0 : RÃ©flexion stratÃ©gique pour '{question}' au '{country}'...")
    try:
        model = genai.GenerativeModel('gemini-1.5-flash')
        prompt = f"""
        Tu es un assistant de recherche juridique expert. Ta premiÃ¨re tÃ¢che est de crÃ©er un plan de recherche structurÃ© pour rÃ©pondre Ã  la question suivante : "{question}" pour le pays : "{country}".
        1.  Analyse la question. Est-ce une question simple, factuelle que tu connais dÃ©jÃ  (ex: capitale, monnaie) ou une question complexe nÃ©cessitant une recherche web ?
        2.  Si la recherche n'est pas nÃ©cessaire, mets "requires_search" Ã  false et explique pourquoi dans "reasoning".
        3.  Si la recherche est nÃ©cessaire, crÃ©e 2 Ã  3 requÃªtes de recherche Google optimisÃ©es. Pense aux termes juridiques et aux organismes officiels locaux (ex: ANPI pour l'investissement, DGI pour les impÃ´ts).
        4.  Liste les domaines web cibles les plus probables pour ces recherches (ex: "anpi-gabon.com", "sante.gouv.ga").
        
        RÃ©ponds UNIQUEMENT avec un objet JSON au format suivant :
        {{
          "requires_search": boolean,
          "reasoning": "string",
          "search_queries": ["string"],
          "target_domains": ["string"]
        }}
        """
        response = model.generate_content(prompt)
        json_text = response.text.strip().replace("```json", "").replace("```", "")
        plan_data = json.loads(json_text)
        plan = SearchPlan(**plan_data)
        print(f"   -> âœ… Plan de recherche crÃ©Ã©. RequÃªte(s) : {plan.search_queries}")
        return plan
        
    except Exception as e:
        print(f"   -> âŒ Erreur durant la rÃ©flexion stratÃ©gique : {e}. Utilisation d'un plan par dÃ©faut.")
        return SearchPlan(
            requires_search=True,
            reasoning="Le plan stratÃ©gique a Ã©chouÃ©, utilisation d'une recherche par dÃ©faut.",
            search_queries=[question],
            target_domains=[]
        )

def find_multiple_official_sites(queries: list[str], country: str, target_domains: list[str]) -> list[str]:
    print(f"ğŸ” Ã‰tape 1 : ExÃ©cution du plan de recherche multi-sources...")
    potential_sources = []
    unwanted_keywords = ['facebook.com', 'youtube.com', 'wikipedia.org', 'scribd.com', 'researchgate.net', 'twitter.com', 'linkedin.com']
    
    for query in queries:
        print(f"   -> Tentative avec la requÃªte : '{query}'")
        url = "https://google.serper.dev/search"
        payload = json.dumps({"q": query, "num": 3})
        headers = {'X-API-KEY': SERPER_API_KEY, 'Content-Type': 'application/json'}
        try:
            response = requests.post(url, headers=headers, data=payload, timeout=10)
            response.raise_for_status()
            results = response.json().get('organic', [])
            
            for result in results:
                link = result['link']
                if any(unwanted in link for unwanted in unwanted_keywords):
                    continue
                if link not in potential_sources:
                    potential_sources.append(link)
        except Exception as e:
            print(f"   -> âŒ Erreur lors de la tentative avec la requÃªte '{query}': {e}")
            continue
    
    official_keywords = GOVERNMENT_SITES_DATABASE.get(country, []) + target_domains
    potential_sources.sort(key=lambda link: any(domain in link for domain in official_keywords), reverse=True)
    
    print(f"   -> âœ… Recherche terminÃ©e. {len(potential_sources)} sources potentielles trouvÃ©es et triÃ©es.")
    return potential_sources[:3]

def scrape_content(source_url: str) -> str | None:
    print(f"      -> ğŸ“„ Extraction du contenu de : {source_url}...")
    if not source_url: return None
    try:
        if source_url.lower().endswith('.pdf'):
            response = requests.get(source_url, timeout=30)
            response.raise_for_status()
            reader = PdfReader(io.BytesIO(response.content))
            return "".join(page.extract_text() for page in reader.pages if page.extract_text())
        else:
            return FirecrawlApp(api_key=FIRECRAWL_API_KEY).scrape_url(source_url).markdown
    except Exception as e:
        print(f"      -> âŒ Erreur lors du scraping : {e}")
        return None

def validate_content_relevance(text_content: str, question: str) -> bool:
    if not text_content: return False
    print(f"      -> ğŸ”¬ Validation rapide de la pertinence du contenu...")
    try:
        model = genai.GenerativeModel('gemini-1.5-flash')
        prompt = f"""Analyse cet extrait. Est-il pertinent pour rÃ©pondre Ã  la question "{question}"? RÃ©ponds SEULEMENT par 'OUI' ou 'NON'. --- EXTRAIT --- {text_content[:4000]}"""
        response = model.generate_content(prompt)
        return "OUI" in response.text.strip().upper()
    except:
        return False

def create_and_search_vector_store(text_content: str, question: str) -> str | None:
    print(f"ğŸ¯ Ã‰tape 3 : Recherche sÃ©mantique dans le document validÃ©...")
    if not text_content: return None
    try:
        chunks = [chunk for chunk in text_content.split('\n\n') if len(chunk.strip()) > 100]
        if not chunks: return None

        embedding_model = 'models/text-embedding-004'
        chunk_embeddings = []
        for i in range(0, len(chunks), 100):
            batch = chunks[i:i+100]
            response = genai.embed_content(model=embedding_model, content=batch, task_type="RETRIEVAL_DOCUMENT")
            chunk_embeddings.extend(response['embedding'])
            if len(chunks) > 100: time.sleep(1.1)

        question_embedding = genai.embed_content(model=embedding_model, content=question, task_type="RETRIEVAL_QUERY")['embedding']
        dot_products = np.dot(np.array(chunk_embeddings), question_embedding)
        top_k_indices = np.argsort(dot_products)[-4:][::-1]
        
        relevant_context = "\n---\n".join([chunks[i] for i in top_k_indices])
        return relevant_context
    except Exception as e:
        print(f"   -> âŒ Erreur lors de la recherche vectorielle : {e}")
        return None

def generate_answer_with_gemini(context: str, question: str, country: str) -> str:
    print(f"âœï¸  Ã‰tape 4 : GÃ©nÃ©ration de la rÃ©ponse finale...")
    if not context: 
        return "La source officielle a Ã©tÃ© analysÃ©e, mais aucun passage pertinent n'a pu Ãªtre identifiÃ© pour rÃ©pondre Ã  cette question."
    
    try:
        model = genai.GenerativeModel('gemini-1.5-flash')
        
        prompt = f"""
        Tu es un assistant juridique factuel et mÃ©ticuleux. Ta seule et unique mission est de rÃ©pondre Ã  la question de l'utilisateur en utilisant **uniquement et strictement** les informations contenues dans le CONTEXTE fourni ci-dessous.

        Il t'est **formellement interdit** d'utiliser tes connaissances gÃ©nÃ©rales, de faire des suppositions ou d'extrapoler.

        **Instructions prÃ©cises :**
        1.  Lis la question : "{question}" (pour le pays : {country}).
        2.  Lis le CONTEXTE fourni.
        3.  Si le CONTEXTE contient une rÃ©ponse directe et spÃ©cifique Ã  la question, formule une rÃ©ponse claire et structurÃ©e en te basant uniquement sur ces informations.
        4.  Si le CONTEXTE ne contient PAS d'informations spÃ©cifiques permettant de rÃ©pondre Ã  la question, tu dois rÃ©pondre **UNIQUEMENT** avec la phrase suivante, et rien d'autre : "Le document source a Ã©tÃ© analysÃ©, mais il ne contient pas d'informations spÃ©cifiques permettant de rÃ©pondre Ã  la question posÃ©e."

        --- CONTEXTE ---
        {context}
        --- FIN DU CONTEXTE ---
        """
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        print(f"   -> âŒ Erreur lors de la gÃ©nÃ©ration finale : {e}")
        return "Une erreur est survenue lors de la gÃ©nÃ©ration de la rÃ©ponse finale."

@app.post("/process_query", response_model=AnswerResponse)
async def get_legal_answer_endpoint(request: QueryRequest):
    user_question = request.question
    user_country = request.country
    cache_key = f"{user_country.lower()}:{user_question.lower()}"
    if cache_key in api_cache:
        print("âœ… RÃ©ponse trouvÃ©e dans le cache ! Renvoi instantanÃ©.")
        return api_cache[cache_key]

    print("-" * 50); print(f"RequÃªte reÃ§ue | Pays : {user_country} | Question : {user_question}"); print("-" * 50)
    
    plan = create_search_plan(user_question, user_country)
    if not plan.requires_search:
        return AnswerResponse(answer=plan.reasoning, source_url=None)

    source_urls = find_multiple_official_sites(plan.search_queries, user_country, plan.target_domains)
    if not source_urls:
        return AnswerResponse(answer="Impossible de trouver une source officielle fiable aprÃ¨s une recherche approfondie.", source_url=None)

    golden_source_url = None
    scraped_content = None
    
    print(f"ğŸ”— Ã‰tape 2 : Validation des {len(source_urls)} sources trouvÃ©es...")
    for i, url in enumerate(source_urls):
        print(f"   -> Tentative avec la source {i+1}/{len(source_urls)} : {url}")
        content = scrape_content(url)
        if content and validate_content_relevance(content, user_question):
            print(f"      -> âœ… Source validÃ©e comme pertinente.")
            golden_source_url = url
            scraped_content = content
            break
        else:
            print(f"      -> âŒ Source jugÃ©e non pertinente ou impossible Ã  lire.")
    
    if not golden_source_url:
        return AnswerResponse(answer="Plusieurs sources officielles ont Ã©tÃ© trouvÃ©es, mais aucune ne semble contenir la rÃ©ponse Ã  votre question spÃ©cifique.", source_url=str(source_urls))
    
    refined_context = create_and_search_vector_store(scraped_content, user_question)
    final_answer = generate_answer_with_gemini(refined_context, user_question, user_country)
    
    response_to_send = AnswerResponse(answer=final_answer, source_url=golden_source_url)
    api_cache[cache_key] = response_to_send
    print("ğŸ’¾ Sauvegarde de la rÃ©ponse dans le cache.")
    
    return response_to_send