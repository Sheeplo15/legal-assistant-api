import os
import io
import json
import requests
import google.generativeai as genai
from dotenv import load_dotenv
from PyPDF2 import PdfReader
from firecrawl import FirecrawlApp
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# --- CHARGEMENT DES VARIABLES D'ENVIRONNEMENT ---
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
FIRECRAWL_API_KEY = os.getenv("FIRECRAWL_API_KEY")
SERPER_API_KEY = os.getenv("SERPER_API_KEY")
genai.configure(api_key=GEMINI_API_KEY)

# --- CONFIGURATION DES SITES GOUVERNEMENTAUX ---
GOVERNMENT_SITES_DATABASE = {
    "Cameroun": [".gouv.cm", "minfi.cm", "minefop.gov.cm", "primeminister.cm"],
    "C√¥te d'Ivoire": [".gouv.ci", "service-public.gouv.ci", "finances.gouv.ci", "dgi.gouv.ci"],
    "Gabon": [".gouv.ga", "dgi.ga", "pme.gouv.ga", "anpigabon.com"],
    "S√©n√©gal": [".gouv.sn", "service-public.gouv.sn", "dgi.gouv.sn", "impotsetdomaines.gouv.sn"]
}


# --- D√âFINITION DE L‚ÄôAPPLICATION ---
app = FastAPI()

# --- CONFIGURATION CORS ---
origins = ["*"]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- SCH√âMAS DE DONN√âES ---
class QueryRequest(BaseModel):
    question: str
    country: str

class AnswerResponse(BaseModel):
    answer: str
    source_url: str | None

# --- FONCTIONS ---

def get_contextual_query(question: str, country: str) -> str:
    print(f"üåç Adaptation de la requ√™te pour le pays : {country}")
    try:
        model = genai.GenerativeModel('gemini-1.5-flash')
        prompt = f"""Tu es un expert en droit compar√©. Ton r√¥le est de traduire un concept juridique commun dans le jargon sp√©cifique d'un pays donn√© pour optimiser une recherche web. Concept de base : "{question}". Pays cible : {country}. Reformule la question en une requ√™te de recherche Google optimale. Ne retourne QUE la requ√™te de recherche, sans aucune autre explication."""
        response = model.generate_content(prompt)
        optimized_query = response.text.strip().replace('"', '')
        print(f"   -> Requ√™te optimis√©e : {optimized_query}")
        return optimized_query
    except Exception as e:
        print(f"   -> Erreur Gemini (fallback sur question originale) : {e}")
        return question

def search_for_official_sites(question: str, country: str) -> str | None:
    print(f"üîé Recherche d‚Äôun site officiel pour : '{question}'...")
    url = "https://google.serper.dev/search"
    payload = json.dumps({"q": question, "num": 5})
    headers = {'X-API-KEY': SERPER_API_KEY, 'Content-Type': 'application/json'}
    try:
        response = requests.post(url, headers=headers, data=payload)
        response.raise_for_status()
        results = response.json()

        if 'organic' not in results or not results['organic']:
            print("‚ùå Aucun r√©sultat organique.")
            return None

        official_keywords = GOVERNMENT_SITES_DATABASE.get(country, ['.gov', '.gouv', 'go.'])
        unwanted = ['facebook.com', 'youtube.com', 'twitter.com', 'linkedin.com', 'wikipedia.org']

        for r in results['organic']:
            link = r['link']
            title = r['title'].lower()
            if any(u in link for u in unwanted):
                print(f"  - Ignor√© (non pertinent) : {link}")
                continue
            if any(k in link for k in official_keywords) or any(k in title for k in official_keywords):
                print(f"‚úÖ Source officielle trouv√©e : {link}")
                return link

        # Si aucun lien officiel, retour par d√©faut
        for r in results['organic']:
            link = r['link']
            if not any(u in link for u in unwanted):
                print(f"‚ö†Ô∏è Source par d√©faut : {link}")
                return link

        print("‚ùå Aucun lien pertinent trouv√©.")
        return None

    except requests.exceptions.RequestException as e:
        print(f"Erreur avec Serper : {e}")
        return None

def scrape_pdf_content(url: str) -> str | None:
    if not url: return None
    print(f"üìÑ T√©l√©chargement du PDF : {url}")
    try:
        response = requests.get(url)
        response.raise_for_status()
        pdf_file = io.BytesIO(response.content)
        pdf_reader = PdfReader(pdf_file)
        full_text = ""
        for page in pdf_reader.pages:
            full_text += page.extract_text() + "\n"
        if full_text:
            print("‚úÖ Texte extrait du PDF.")
            return full_text
        else:
            print("‚ùå PDF vide ou illisible.")
            return None
    except Exception as e:
        print(f"Erreur lors du scraping PDF : {e}")
        return None

def scrape_website_content(url: str) -> str | None:
    if not url: return None
    print(f"üî• Scraping du site web : {url}")
    try:
        app_firecrawl = FirecrawlApp(api_key=FIRECRAWL_API_KEY)
        scraped_data = app_firecrawl.scrape_url(url)
        content = scraped_data.markdown
        if content:
            print("‚úÖ Contenu extrait du site.")
            return content
        else:
            print("‚ùå Aucun contenu trouv√©.")
            return None
    except Exception as e:
        print(f"Erreur Firecrawl : {e}")
        return None

def generate_answer_with_gemini(context: str, question: str, country: str) -> str:
    if not context:
        return "Je n'ai pas pu extraire d'informations de la source pour r√©pondre √† votre question."
    print("üß† G√©n√©ration de r√©ponse avec Gemini...")
    try:
        model = genai.GenerativeModel('gemini-1.5-flash')
        prompt = f"""
        Tu es un assistant juridique IA. Ta mission est de r√©pondre de mani√®re pr√©cise et factuelle √† la question de l'utilisateur en te basant EXCLUSIVEMENT sur le texte source fourni.
        Pays concern√© : {country}
        Question : "{question}"
        Texte source : --- {context} ---
        Instructions : Lis le texte. Formule une r√©ponse claire et structur√©e. Si l'information n'est pas pr√©sente, indique clairement : "Je n'ai pas pu trouver d'informations pr√©cises sur ce sujet dans la source officielle consult√©e." Ne jamais inventer d'informations.
        """
        response = model.generate_content(prompt)
        print("‚úÖ R√©ponse g√©n√©r√©e.")
        return response.text
    except Exception as e:
        print(f"Erreur Gemini : {e}")
        return "Une erreur est survenue lors de la g√©n√©ration de la r√©ponse."

# --- ENDPOINT PRINCIPAL ---
@app.post("/process_query", response_model=AnswerResponse)
async def get_legal_answer_endpoint(request: QueryRequest):
    user_question = request.question
    user_country = request.country
    print("-" * 50)
    print(f"üåê Nouvelle requ√™te re√ßue | Pays : {user_country} | Question : {user_question}")
    print("-" * 50)

    optimized_question = get_contextual_query(user_question, user_country)
    source_url = search_for_official_sites(optimized_question, user_country)

    # --- Aiguillage intelligent PDF / Web ---
    scraped_content = None
    if source_url:
        if source_url.lower().endswith('.pdf'):
            print("üìå Type de source d√©tect√© : PDF")
            scraped_content = scrape_pdf_content(source_url)
        else:
            print("üìå Type de source d√©tect√© : Page web")
            scraped_content = scrape_website_content(source_url)

    final_answer = generate_answer_with_gemini(scraped_content, user_question, user_country)

    return AnswerResponse(answer=final_answer, source_url=source_url)
